{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPdT63ipf6GQUiuWWu611J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atilaye/BioFaceNet-Python-Implementation/blob/master/BioFaceNet_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This code is a Python translation of the MATLAB implementation of BioFaceNet, originally provided by the authors of the paper:\n",
        "S. Alhagry, R. Bahgat, A. Elsayed, \"BioFaceNet: Deep Convolutional Neural Network for Face Photo-Sketch Recognition,\" arXiv:1908.10578 [cs.CV], 2019.\n",
        "https://arxiv.org/pdf/1908.10578\n",
        "\n",
        "Original MATLAB code repository: https://github.com/ssma502/BioFaces\n",
        "\n",
        "Translated by: Ameya Tilaye\n",
        "Date: 9/22/2024\n",
        "\n",
        "\n",
        "\n",
        "CelebA dataset:\n",
        "@inproceedings{conf/iccv/LiuLWT15,\n",
        "  added-at = {2018-10-09T00:00:00.000+0200},\n",
        "  author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},\n",
        "  biburl = {https://www.bibsonomy.org/bibtex/250e4959be61db325d2f02c1d8cd7bfbb/dblp},\n",
        "  booktitle = {ICCV},\n",
        "  crossref = {conf/iccv/2015},\n",
        "  ee = {http://doi.ieeecomputersociety.org/10.1109/ICCV.2015.425},\n",
        "  interhash = {3f735aaa11957e73914bbe2ca9d5e702},\n",
        "  intrahash = {50e4959be61db325d2f02c1d8cd7bfbb},\n",
        "  isbn = {978-1-4673-8391-2},\n",
        "  keywords = {dblp},\n",
        "  pages = {3730-3738},\n",
        "  publisher = {IEEE Computer Society},\n",
        "  timestamp = {2018-10-11T11:43:28.000+0200},\n",
        "  title = {Deep Learning Face Attributes in the Wild.},\n",
        "  url = {http://dblp.uni-trier.de/db/conf/iccv/iccv2015.html#LiuLWT15},\n",
        "  year = 2015\n",
        "}\n"
      ],
      "metadata": {
        "id": "hYSzjuRo5YK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets"
      ],
      "metadata": {
        "id": "865hEhgX5dos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io as spio\n",
        "from scipy.io import loadmat\n",
        "import torch\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/MyDrive/Visual Machines Group/')  #CelebA is downloaded from Google Drive\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "_En28PZK51Ep",
        "outputId": "6e189a0c-6547-47b6-aadf-7e31897d28a0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mountpoint must not contain a space.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5363e2b809ec>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Visual Machines Group/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmountpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not contain a space.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VERTEX_PRODUCT'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'COLAB_ENTERPRISE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must not contain a space."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import celebmat here\n",
        "import torchvision\n",
        "\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "class CelebDataset(Dataset):                #importing CelebA dataset\n",
        "      def __init__(self,data_dir,partition_file_path,split,transform):\n",
        "          self.partition_file = pd.read_csv(partition_file_path)\n",
        "          self.data_dir = data_dir\n",
        "          self.split = split\n",
        "          self.transform = transform\n",
        "      def __len__(self):\n",
        "          self.partition_file_sub = self.partition_file[self.partition_file[\"partition\"].isin(self.split)]\n",
        "          return len(self.partition_file_sub)\n",
        "      def __getitem__(self,idx):\n",
        "          img_name = os.path.join(self.data_dir,\n",
        "                                  self.partition_file_sub.iloc[idx, 0])\n",
        "          image = io.imread(img_name)\n",
        "          if self.transform:\n",
        "              image = self.transform(image)\n",
        "          return image\n",
        "\n",
        "batch_size = 50000\n",
        "\n",
        "transform = transforms.Compose(       #batch transformation\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "#download CelebA dataset\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(celeba_data,batch_size=4,shuffle=True,num_workers = *args.nThreads) #change batch size once you get this to work\n",
        "\n",
        "'''\n",
        "'''\n",
        "torchvision.datasets\n",
        "\n",
        "imagenet_data = torchvision.datasets.ImageNet('path/to/imagenet_root/')\n",
        "data_loader = torch.utils.data.DataLoader(imagenet_data,\n",
        "                                          batch_size=4,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=args.nThreads)\n",
        "\n",
        "celeba:\n",
        "\n",
        "torchvision.datasets.CelebA(root: str, split: str = 'train', target_type: Union[List[str], str] = 'attr', transform: Optional[Callable] = None,target_transform: Optional[Callable] = None, download: bool = False)\n",
        "'''"
      ],
      "metadata": {
        "id": "QQVsWumN5_cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Newskincolour = spio.loadmat('/content/drive/MyDrive/Visual Machines Group/Newskincolour.mat') #'imdb/celebaimdb.mat'"
      ],
      "metadata": {
        "id": "M63G2TyE7Wrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tmatrix = spio.loadmat('/content/drive/MyDrive/Visual Machines Group/Tmatrix.mat')"
      ],
      "metadata": {
        "id": "sGGCyhq9F8vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "illF = spio.loadmat('/content/drive/MyDrive/Visual Machines Group/illF.mat')"
      ],
      "metadata": {
        "id": "ICkJUeKZEhFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "illumA = spio.loadmat('/content/drive/MyDrive/Visual Machines Group/illumA.mat')"
      ],
      "metadata": {
        "id": "ON33Q1XBEgxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "illumDmeasured = spio.loadmat('/content/drive/MyDrive/Visual Machines Group/illumDmeasured.mat')"
      ],
      "metadata": {
        "id": "FWrXf5bwEgiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmf = spio.loadmat('/content/drive/MyDrive/Visual Machines Group/rgbCMF.mat')\n"
      ],
      "metadata": {
        "id": "1rwDMC7CIyl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xyz_space = spio.loadmat('/content/drive/MyDrive/Visual Machines Group/XYZspace (1).mat')"
      ],
      "metadata": {
        "id": "S_fwnTpkIyd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CameraSensitivityPCA.m\n",
        "#PCA Model for Camera Sensitivities\n",
        "#function [mu,PC,EV]= CameraSensitivityPCA(cmf) returns array\n",
        "mu, PC, EVpca = CameraSensitivityPCA(cmf)\n",
        "\n",
        "def diagonalize(A): #Diagonalized matrix D = E^-1 * A * E\n",
        "  #A = np.sqrt(EV[1:2])\n",
        "  E = np.linalg.eig(A)\n",
        "  E_inv = np.linalg.inv(A)\n",
        "  X = np.dot(E_inv,A)\n",
        "  D = np.dot(X,E)\n",
        "  return D\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "def CameraSensitivityPCA(cmf):\n",
        "  X = np.zeros((99,28))\n",
        "  Y = np.zeros((99,28))\n",
        "  redS = cmf.rgbCMF[1][1] #not sure if I need the cmf.\n",
        "  greenS = cmf.rgbCMF[1][2]\n",
        "  blueS = cmf.rgbCMF[1][3]\n",
        "  for i in range(1,28):\n",
        "    a = redS[:,i]\n",
        "    b = np.sum(redS[:,i])\n",
        "    Y[1:33,i]= np.linalg.lstsq(a.T, b.T)[0].T #np.true_divide(redS[:,i],sum(redS[:,i])) #true right array division\n",
        "    c = greenS[:,i]\n",
        "    d = np.sum(greenS[:,i])\n",
        "    Y[34:66,i]= np.linalg.lstsq(c.T, d.T)[0].T #np.true_divide(greenS[:,i]) #greenS[:,i]./sum(greenS(:,i))\n",
        "    e = blueS[:,i]\n",
        "    f = np.sum(blueS[:,i])\n",
        "    Y[67:99,i]= np.linalg.lstsq(e.T, f.T)[0].T #blueS(:,i)./sum(blueS(:,i))\n",
        "    break\n",
        "  pca = PCA(Y.transpose())  #[PC,~,EV,~,explained,mu] = pca(Y'); #principal component coefficients of the matrix transpose of Y\n",
        "  mu = np.float32(mu.transpose())\n",
        "  EV = np.float32(EV[1:2])\n",
        "  A = np.sqrt(EV[1:2])\n",
        "  PC = np.float32(PC[:,1:2] * diagonalize(A)) #PC = np.float32(PC[:,1:2] * diagonalized sqrt(EV[1:2]))\n",
        "  return [mu,PC,EV]"
      ],
      "metadata": {
        "id": "vhDbQZ8yPRzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setup.m\n",
        "#single to np.float32\n",
        "\n",
        "import torch\n",
        "\n",
        "#[mu,PC,EVpca] = CameraSensitivityPCA(cmf);\n",
        "\n",
        "#predicted vectors' sizes\n",
        "LightVectorSize = np.float32(15)\n",
        "wavelength = np.float32(33)\n",
        "bSize = np.float32(2)\n",
        "\n",
        "#normalize illuminations\n",
        "illF = np.float32(illF.reshape(1,1,33,12))\n",
        "\n",
        "\n",
        "illumDmeasured = (illumDmeasured.transpose())\n",
        "illumDmeasured = np.reshape(illumDmeasured,(1,1,33,22))\n",
        "\n",
        "#A (what is A?)\n",
        "#illumA         = single(illumA./sum(illumA(:)));\n",
        "illumA =  np.float32(np.linalg.lstsq(illumA.T, np.sum(illumA[:]).T)[0].T)\n",
        "\n",
        "e = blueS[:, i]  # Extract the i-th column\n",
        "f = np.sum(blueS[:, i])  # Sum of the i-th column\n",
        "Y[67:99, i] = blueS[:, i] / np.sum(blueS[:, i])  # Normalized column\n",
        "\n",
        "#D\n",
        "illumDNorm = np.float32(np.zeros(1,1,33,22))\n",
        "for i in range(1,22):\n",
        "  a = illumDmeasured[1,1,:,i]\n",
        "  b = np.sum(illumDmeasured[1,1,:,i])\n",
        "  illumDNorm[1,1,:,i] = np.linalg.lstsq(a.T, b.T)[0].T\n",
        "  break\n",
        "# Normalizing illumF\n",
        "illumFNorm = np.zeros((1, 1, 33, 12), dtype=np.float32)\n",
        "for i in range(12):  # Python indexing starts at 0, MATLAB uses 1-based indexing\n",
        "    illumFNorm[0, 0, :, i] = illF[0, 0, :, i] / np.sum(illF[0, 0, :, i])\n",
        "\n",
        "\n",
        "# Define mu and PC as PyTorch tensors\n",
        "mu = torch.tensor(mu, dtype=torch.float32, requires_grad=False)  # Create tensor\n",
        "PC = torch.tensor(PC, dtype=torch.float32, requires_grad=False)  # Create tensor\n",
        "\n",
        "# Move to GPU\n",
        "mu = mu.cuda()  # Transfer to GPU\n",
        "PC = PC.cuda()\n",
        "\n",
        "# Same for illumA and illumFNorm\n",
        "illumA = torch.tensor(illumA, dtype=torch.float32, requires_grad=False)\n",
        "illumA = illumA.cuda()\n",
        "\n",
        "illumFNorm = torch.tensor(illumFNorm, dtype=torch.float32, requires_grad=False)\n",
        "illumFNorm = illumFNorm.cuda()\n"
      ],
      "metadata": {
        "id": "SzY1BOb1RRMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#findT.m\n",
        "def findT(Tmatrix,BGrid): #BGrid defined in scalingNet.m\n",
        "  Tmatrix = spio.loadmat('/content/drive/MyDrive/Visual Machines Group/Tmatrix.mat')\n",
        "  T_RAW2XYZ = nn.Bilinear(Tmatrix,BGrid)\n",
        ""
      ],
      "metadata": {
        "id": "Y94tnUtSRBG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#fcn_multipleDecoders.m\n",
        "def multipleDecoders(x,y,nfilters,doubleconv):\n",
        "  '''\n",
        "  %FCN Build an autonn fully convolutional network,image to image tasks, skip connections from each encoder layer to corresponding\n",
        "% decoder layer\n",
        "%   Inputs kept the same:\n",
        "%       nfilters - vector of filter sizes, 1:length-1 are used in the\n",
        "%       contractive part of the network, the final value is the number of\n",
        "%       filters applied at the lowest resolution before upsampling begins\n",
        "%       x - input feature map as autonn layer\n",
        "%       nclass - number of channels in output feature map\n",
        "%\n",
        "%\n",
        "%   Outputs kept the same:\n",
        "%       x - image to image prediction\n",
        "%       y - output of lowest resolution - can be fed into fully connected\n",
        "%       layers\n",
        "\n",
        "  '''\n",
        "#nfilters = [length for length in range (1,length-1)]\n",
        "nfilters = [32,32,64,96,128,256] #don't know how to read in array in Python\n",
        "nlayers = np.array(np.size(nfilters)) #nlayers is a vector\n",
        "for i in range(1, nlayers-1):\n",
        "    if i == 1:\n",
        "        #x = nn.Conv1d(x,[3 3 3 nfilters(i)], np.pad()) #figure out padding\n",
        "        x = nn.Conv1d(i,np.size(nlayers),np.pad([3, 3, 3, nfilters[i]]), stride = 1)\n",
        "    else:\n",
        "        #x = nn.Conv1d(x, np.pad([3 3 nfilters(i-1) nfilters(i)]))\n",
        "        x = nn.Conv1d(i,np.size(nlayers), np.pad([3, 3, nfilters[i-1], nfilters[i]]), stride = 1)\n",
        "    break\n",
        "    x = nn.BatchNorm1d(x)\n",
        "    if doubleconv:#boolean\n",
        "      x = nn.ReLU(x)\n",
        "      #x = nn.Conv1d(x,[3 3 nfilters(i) nfilters(i)] , np.pad())\n",
        "      x = nn.Conv1d(x,np.pad([3, 3, nfilters[i], nfilters[i]]), stride = 1)\n",
        "      x = nn.BatchNorm1d(x) #batch normalization\n",
        "      x = nn.ReLU(x)\n",
        "      #x = nn.Conv1d(x,[3 3 nfilters(i) nfilters(i)] , np.pad())\n",
        "      x = nn.Conv1d(x,np.pad([3, 3, nfilters[i], nfilters[i]]), stride = 1)\n",
        "      x = nn.BatchNorm1d(x)\n",
        "    break\n",
        "    x_skip[i] = nn.ReLu(x) #x_skip{i} = vl_nnrelu(x);\n",
        "    x = nn.MaxPool1d(x_skip[i],2,stride = 2) #x = vl_nnpool(x_skip{i}, 2, 'stride', 2) ;\n",
        "break\n",
        "\n",
        "x = nn.Conv1d(x,np.pad([3, 3, nfilters[nlayers-1], nfilters[nlayers]]), stride = 1)\n",
        "x = nn.BatchNorm1d(x) #batch normalization\n",
        "y = nn.ReLU(x)\n",
        "if doubleconv:\n",
        "   x = nn.Conv1d(y,np.pad([3, 3, nfilters[nlayers], nfilters[nlayers]]), stride = 1)\n",
        "   x = nn.BatchNorm1d(x) #batch normalization\n",
        "   y = nn.ReLU(x)\n",
        "   x = nn.Conv1d(y,np.pad([3, 3, nfilters[nlayers], nfilters[nlayers]]), stride = 1)\n",
        "   x = nn.BatchNorm1d(x) #batch normalization\n",
        "   y = nn.ReLU(x)\n",
        "break\n",
        "\n",
        "\n",
        "#Decoders\n",
        "#vl_nnupsample = Layer.fromFunction(@autonn_upSample);\n",
        "\n",
        "for c in range(1, nclass):\n",
        "  for i in range(nlayers-1,-1,1):\n",
        "    if i == nlayers-1:\n",
        "    #m = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "      x = nn.upSample(y)\n",
        "    else:\n",
        "      x = nn.upSample(x)\n",
        "      break\n",
        "    #x = cat(3,x,x_skip{i});\n",
        "      x = nn.Conv1d(x,np.pad([3, 3, nfilters[i]+nfilters[i+1], nfilters[i]]), stride = 1)\n",
        "      x = nn.BatchNorm1d(x) #batch normalization\n",
        "      x = nn.ReLU(x)\n",
        "\n",
        "    if doubleconv:\n",
        "      x = nn.Conv1d(x,np.pad([3, 3, nfilters[i], nfilters[i]]), stride = 1)\n",
        "      x = nn.BatchNorm1d(x) #batch normalization\n",
        "      x = nn.ReLU(x)\n",
        "\n",
        "      x = nn.Conv1d(x,np.pad([3, 3, nfilters[i], nfilters[i]]), stride = 1)\n",
        "      x = nn.BatchNorm1d(x) #batch normalization\n",
        "      x = nn.ReLU(x)\n",
        "    break\n",
        "  break\n",
        "\n",
        "  #Final Predictions\n",
        "\n",
        "  x = nn.Conv1d(x,np.pad([3, 3, nfilters[1], 1]), stride = 1)\n",
        "  if c==1:\n",
        "    z = x\n",
        "  else:\n",
        "    z = np.concatenate((z,x), axis = 3) # z = cat(3,z,x);\n",
        "  break\n",
        "break"
      ],
      "metadata": {
        "id": "EoLVY3DRRBDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN.m\n",
        "\n",
        "def CNN(images,nfilters,nclass,LightVectorSize,bSize):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "Inputs:,\n",
        "    images           : input to CNN\n",
        "     nfilters         : vector of filter sizes\n",
        "    nclass           : number of output maps\n",
        "    lightVectorLSize : 15\n",
        "     bsize            : 2\n",
        "Output:\n",
        "     weightA    : 1 x 1 x 1 x B\n",
        "     weightD    : 1 x 1 x 1 x B\n",
        "     CCT        : 1 x 1 x 1 x B\n",
        "     Fweights   : 1 x 1 x 12 x B\n",
        "     b          : 2 x nbatch\n",
        "\n",
        "  \"\"\"\n",
        "-------------------------------- CNN -------------------------------------\n",
        "x,y  = fcn_multipleDecoders(nfilters,images,nclass, True)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Assuming `y` is a tensor of shape (batch_size, channels, height, width)\n",
        "\n",
        "# FC1 (Convolution + BatchNorm + ReLU)\n",
        "fc1 = nn.Conv2d(512, 512, kernel_size=4)(y)  # [4, 4, 512, 512]\n",
        "fc1 = nn.BatchNorm2d(512)(fc1)\n",
        "fc1 = F.relu(fc1)\n",
        "\n",
        "# FC2 (Convolution + BatchNorm + ReLU)\n",
        "fc2 = nn.Conv2d(512, 512, kernel_size=1)(fc1)  # [1, 1, 512, 512]\n",
        "fc2 = nn.BatchNorm2d(512)(fc2)\n",
        "fc2 = F.relu(fc2)\n",
        "\n",
        "# FC3 (Convolution)\n",
        "dims = LightVectorSize + bSize  # Set this variable beforehand\n",
        "prediction = nn.Conv2d(512, dims, kernel_size=1)(fc2)\n",
        "prediction.name = 'prediction'\n",
        "\n",
        "# Illumination parameters\n",
        "lightingparameters = prediction[:, :, :LightVectorSize, :]\n",
        "\n",
        "# Camera parameters\n",
        "nbatch = prediction.shape[3]  # Assuming batch_size is the 4th dimension\n",
        "b = prediction[:, :, LightVectorSize:LightVectorSize + bSize, :].view(bSize, nbatch)\n",
        "\n",
        "# Predicted Maps\n",
        "fmel = x[:, :, 0, :]\n",
        "fblood = x[:, :, 1, :]\n",
        "Shading = x[:, :, 2, :]\n",
        "specmask = x[:, :, 3, :]\n",
        "\n"
      ],
      "metadata": {
        "id": "RgcjkpoHI3Hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ImageFormation.m\n",
        "\n",
        "def ImageFormation (R_total, Sr,Sg,Sb,e,Specularities,Shading):\n",
        "  \"\"\"\n",
        "Inputs:\n",
        "    R_total       : H X W X 33 X nbatch\n",
        "    Shading       : H X W X 1 X nbatch\n",
        "    Specularities : H X W X 1 X nbatch\n",
        "    Sr,Sg,Sb      : 1 x 1 x 33 x nbatch\n",
        "    e             : 1 x 1 x 33 x nbatch\n",
        "Output:\n",
        "    rgbim : H x W x 1 x nbatch\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "\n",
        " #--------------------------- Image Formation -------------------------------\n",
        "spectraRef = R_total * e  # Element-wise multiplication in NumPy\n",
        "\n",
        "# Calculate the r, g, b channels by summing along axis 3 (channel dimension)\n",
        "rChannel = np.sum(spectraRef * Sr, axis=2)\n",
        "gChannel = np.sum(spectraRef * Sg, axis=2)\n",
        "bChannel = np.sum(spectraRef * Sb, axis=2)\n",
        "\n",
        "# Stack the r, g, b channels along a new axis (axis 2, equivalent to concatenation along 3rd axis in MATLAB)\n",
        "diffuseAlbedo = np.stack((rChannel, gChannel, bChannel), axis=2)  # Shape: H x W x 3\n",
        "\n",
        "# --------------------------- Shaded Diffuse --------------------------------\n",
        "\n",
        "# Element-wise multiplication to get Shaded Diffuse\n",
        "ShadedDiffuse = diffuseAlbedo * Shading  # Assuming element-wise multiplication\n",
        "\n",
        "# --------------------------- Raw Appearance --------------------------------\n",
        "# Sum the ShadedDiffuse with Specularities\n",
        "rawAppearance = ShadedDiffuse + Specularities  # Assuming element-wise addition\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_r4k6byrPwwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cameraModel.m\n",
        "\n",
        "def cameraModel(mu,PC,b,wavelength):\n",
        "\"\"\"\n",
        "Inputs:\n",
        "  mu         : 1 x 1 x 1 x B\n",
        "  PC         : 1 x 1 x 1 x B\n",
        "  b          : 1 x 1 x 2 x B\n",
        "  wavelength : 33\n",
        "\n",
        "Outputs:\n",
        "  Sr,Sg,Sb   : 1 x 1 x 33 x B\n",
        "  nbatch = size(b,2);\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# PCA model\n",
        "S = np.dot(PC, b) + mu  # Matrix multiplication + adding mean vector\n",
        "\n",
        "# ReLU activation (clamp negative values to zero)\n",
        "S = np.maximum(S, 0)\n",
        "\n",
        "# Split S into Sr, Sg, Sb\n",
        "Sr = np.reshape(S[:wavelength, :], (1, 1, wavelength, nbatch))\n",
        "Sg = np.reshape(S[wavelength:wavelength*2, :], (1, 1, wavelength, nbatch))\n",
        "Sb = np.reshape(S[wavelength*2:wavelength*3, :], (1, 1, wavelength, nbatch))\n",
        "\n",
        "# Optionally assign a name if necessary\n",
        "S_name = 'S'\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7mzZPItNPzGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#computeSpecularities.m\n",
        "\n",
        "def computeSpecularities(specmask,lightcolour):\n",
        "\n",
        "\"\"\"\n",
        "Inputs:\n",
        "  specmask          : H x W x 1 x B\n",
        "  lightcolour      : 1 x 1 x 3 x B\n",
        "Output:\n",
        "  Specularities    : H x W x 1 x B\n",
        "\"\"\"\n",
        "Specularities = specmask * lightcolour\n"
      ],
      "metadata": {
        "id": "c0lwdLXLP34G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#computelightcolour.m\n",
        "\n",
        "def computelightcolour(e,Sr,Sg,Sb):\n",
        "  \"\"\"\n",
        "Inputs:\n",
        "  Sr,Sg,Sb         : 1 x 1 x 33 x B\n",
        "  e                : 1 x 1 x 33 x B\n",
        "Output:\n",
        "  lightcolour        : 1 x 1 x 3 x B\n",
        "\n",
        "\"\"\"\n",
        "------------------------ lightcolour ---------------------------------------------\n",
        "\n",
        "# Element-wise multiplication and summation along the third axis (axis=2 in Python)\n",
        "lightcolour = np.array([np.sum(Sr * e, axis=2), np.sum(Sg * e, axis=2), np.sum(Sb * e, axis=2)])\n",
        "\n",
        "# Reshape to (1, 1, 3, size_of_last_dimension)\n",
        "lightcolour = lightcolour.reshape((1, 1, 3, lightcolour.shape[1]))\n",
        "\n"
      ],
      "metadata": {
        "id": "w8u9aTOYP8Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fromRawTosRGB.m\n",
        "\n",
        "def fromRawTosRGB(imWB,T_RAW2XYZ):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "Inputs:\n",
        " imWB: H X W X 3 X B\n",
        " Tmatrix :  128 X 128 X 9\n",
        "Output:\n",
        " sRGBim : H x W x 3 x B\n",
        "\n",
        " \"\"\"\n",
        "\n",
        "  # Compute Ix, Iy, Iz\n",
        "Ix = (T_RAW2XYZ[0, 0, 0, :] * imWB[:, :, 0, :] + T_RAW2XYZ[0, 0, 3, :] * imWB[:, :, 1, :] + T_RAW2XYZ[0, 0, 6, :] * imWB[:, :, 2, :])\n",
        "\n",
        "Iy = (T_RAW2XYZ[0, 0, 1, :] * imWB[:, :, 0, :] + T_RAW2XYZ[0, 0, 4, :] * imWB[:, :, 1, :] + T_RAW2XYZ[0, 0, 7, :] * imWB[:, :, 2, :])\n",
        "\n",
        "Iz = (T_RAW2XYZ[0, 0, 2, :] * imWB[:, :, 0, :] + T_RAW2XYZ[0, 0, 5, :] * imWB[:, :, 1, :] + T_RAW2XYZ[0, 0, 8, :] * imWB[:, :, 2, :])\n",
        "\n",
        "# Concatenate Ix, Iy, Iz along the third dimension\n",
        "Ixyz = np.stack((Ix, Iy, Iz), axis=2)\n",
        "\n",
        "# Define the transformation matrix\n",
        "Txyzrgb = np.array([[3.2406, -1.5372, -0.4986],[-0.9689,  1.8758,  0.0415], [0.0557, -0.2040,  1.057]], dtype=np.float32)\n",
        "\n",
        "# Check if imWB is a special layer\n",
        "if isinstance(imWB, Layer):\n",
        "    Txyzrgb = Param(value=Txyzrgb, learning_rate=0)\n",
        "    Txyzrgb.name = 'Txyzrgb'\n",
        "\n",
        "# Compute R, G, B channels\n",
        "R = (Txyzrgb[0, 0] * Ixyz[:, :, 0, :] + Txyzrgb[0, 1] * Ixyz[:, :, 1, :] + Txyzrgb[0, 2] * Ixyz[:, :, 2, :])\n",
        "\n",
        "G = (Txyzrgb[1, 0] * Ixyz[:, :, 0, :] + Txyzrgb[1, 1] * Ixyz[:, :, 1, :] + Txyzrgb[1, 2] * Ixyz[:, :, 2, :])\n",
        "\n",
        "B = (Txyzrgb[2, 0] * Ixyz[:, :, 0, :] + Txyzrgb[2, 1] * Ixyz[:, :, 1, :] + Txyzrgb[2, 2] * Ixyz[:, :, 2, :])\n",
        "\n",
        "# Concatenate R, G, B along the third dimension\n",
        "sRGBim = np.stack((R, G, B), axis=2)\n",
        "\n",
        "# Apply ReLU activation (clamp negative values to zero)\n",
        "sRGBim = np.maximum(sRGBim, 0)\n"
      ],
      "metadata": {
        "id": "KckDiHgCQAo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BiotoSpectralRef.m\n",
        "\n",
        "def BiotoSpectralRef(fmel,fblood,Newskincolour):\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Inputs:\n",
        "  fmel             : H x W x 1 x B\n",
        "  fblood           : H x W x 1 x B\n",
        "  Newskincolour    : 256 x 256 x 33 x B\n",
        "Output:\n",
        "  R_total          : H x W x 33 x B\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Concatenate fblood and fmel along the third dimension\n",
        "BiophysicalMaps = torch.cat((fblood, fmel), dim=2)\n",
        "\n",
        "# Permute the dimensions: 2 x H x W x B -> B x H x W x 2\n",
        "BiophysicalMaps = BiophysicalMaps.permute(3, 1, 2, 0)\n",
        "\n",
        "\n",
        "# Perform bilinear interpolation using PyTorch\n",
        "\n",
        "R_total = F.interpolate(Newskincolour, size=BiophysicalMaps.shape[2:], mode='bilinear', align_corners=False)"
      ],
      "metadata": {
        "id": "omgO1fdVQCW9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}